{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation \n",
    "\n",
    "In diesem Notebook trainieren wir einen Classifier. Aus Beispielen lernt der Classifier, zu welcher Klasse ein Element gehört, und kann neue Elemente mit den gelernten Regeln einordnen. \n",
    "\n",
    "Wir lesen zunächst Dokumente aus 4 Wikipedia-Kategorien ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texten sammeln (API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SaveWiki\n",
    "\n",
    "SaveWiki.downloadWikiCat('','Wald')\n",
    "SaveWiki.downloadWikiCat('Tier','Tier')\n",
    "#SaveWiki.downloadWikiCat('Bösartige Tumorbildung','krebs')\n",
    "#SaveWiki.downloadWikiCat('Krankheitsbild in der Kardiologie','kardiologie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Texten aufmachen und lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "\n",
    "def readtext(dateiname):\n",
    "    text = ''\n",
    "    d = codecs.open(dateiname,'r','utf8')\n",
    "    for zeile in d:\n",
    "        text += str(zeile)\n",
    "    d.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Als Adenokarzinom bezeichnet man einen bösartigen (malignen) von der Deckzellschicht (Epithel) ausgehenden Tumor, der aus Drüsengewebe hervorgegangen ist. Die gutartige (benigne) Zellveränderung von Drüsengewebe nennt man dagegen Adenom.\n",
      "Adenokarzinome kommen vor allem im Bereich der Verdauungsorgan\n"
     ]
    }
   ],
   "source": [
    "bsptext= readtext('krebs/Adenokarzinom.txt')\n",
    "print(bsptext[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalen des Textes auswählen\n",
    "\n",
    "***stopwords ausschließen***\n",
    "\n",
    "***Zeichen ausschließen***\n",
    "\n",
    "***closed class words ausschließen***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from HanTa import HanoverTagger as ht\n",
    "from collections import Counter\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('german')\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "def closed_class(pos):\n",
    "    if pos[0] == '$':\n",
    "        return True\n",
    "    elif pos in [\"APPR\", \"APPRART\", \"APPO\", \"APZR\", \"ART\", \"KOUI\", \"KOUS\", \"KON\", \"KOKOM\", \"PDS\", \"PDAT\", \"PIS\", \"PIAT\", \"PIDAT\", \"PPER\", \"PPOSS\", \"PPOSAT\", \"PRELS\", \"PRELAT\", \"PRF\", \"PWS\", \"PWAT\", \"PWAV\", \"PAV\", \"PTKZU\", \"PTKNEG\", \"VAFIN\", \"VAIMP\", \"VAINF\", \"VAPP\", \"VMFIN\", \"VMINF\", \"VMPP\"]:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def features_from_text(text):\n",
    "    wordcounts = Counter()\n",
    "    tlen = 0\n",
    "    \n",
    "    satzliste =  nltk.sent_tokenize(text,language='german')\n",
    "    for satz in satzliste:\n",
    "        tokens =  nltk.word_tokenize(satz,language='german')\n",
    "        tokens = [lemma for (word,lemma,pos) in tagger.tag_sent(tokens) if not closed_class(pos)]\n",
    "        tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "        tokens = [t for t in tokens if re.search('^\\w+$',t)]\n",
    "        tlen += len(tokens)\n",
    "        wordcounts.update(tokens)\n",
    "\n",
    "    return {w:wordcounts[w]/tlen for w in wordcounts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir versuchen aus jede Klasse 50 Dokumente zu lesen, die nicht extrem kurz oder lang sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def read_data(directories):\n",
    "    docs = []\n",
    "    for directory in directories:\n",
    "        dirsize = 0\n",
    "        for file in glob.glob(directory+\"/*.txt\"):\n",
    "            text = readtext(file)\n",
    "            if len(text) > 500 and len(text) < 10000:\n",
    "                docs.append((features_from_text(text),directory))\n",
    "                dirsize += 1\n",
    "            if dirsize >= 50:\n",
    "                break\n",
    "    return docs\n",
    "\n",
    "data = read_data(['infekt','krebs','pneumologie','kardiologie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'akut': 0.0273972602739726,\n",
       "  'eitrig': 0.0319634703196347,\n",
       "  'Thyreoiditis': 0.0365296803652968,\n",
       "  'handeln': 0.0045662100456621,\n",
       "  'selten': 0.0091324200913242,\n",
       "  'schmerzhaft': 0.0045662100456621,\n",
       "  'Entzündung': 0.0136986301369863,\n",
       "  'Schilddrüse': 0.0228310502283105,\n",
       "  'meist': 0.0045662100456621,\n",
       "  'Infektion': 0.0228310502283105,\n",
       "  'Bakterie': 0.0091324200913242,\n",
       "  'zurückführen': 0.0045662100456621,\n",
       "  'sehen': 0.0045662100456621,\n",
       "  'infektiöse': 0.0045662100456621,\n",
       "  'thyreoiditis': 0.0091324200913242,\n",
       "  'Ursache': 0.0045662100456621,\n",
       "  'Krankheitsentstehung': 0.0045662100456621,\n",
       "  'häufig': 0.0091324200913242,\n",
       "  'Erreger': 0.0045662100456621,\n",
       "  'grampositiv': 0.0045662100456621,\n",
       "  'streptococcus': 0.0091324200913242,\n",
       "  'pyogenes': 0.0045662100456621,\n",
       "  'pneumoniae': 0.0045662100456621,\n",
       "  'staphylococcus': 0.0045662100456621,\n",
       "  'aureus': 0.0045662100456621,\n",
       "  'gelingen': 0.0045662100456621,\n",
       "  'Regel': 0.0045662100456621,\n",
       "  'Lymphgefäße': 0.0045662100456621,\n",
       "  'Schilddrüsengewebe': 0.0045662100456621,\n",
       "  'hämatogen': 0.0045662100456621,\n",
       "  'lymphogen': 0.0045662100456621,\n",
       "  'Infektionsweg': 0.0045662100456621,\n",
       "  'Ausgangspunkt': 0.0045662100456621,\n",
       "  'bakteriell': 0.0091324200913242,\n",
       "  'Halsbereich': 0.0091324200913242,\n",
       "  'Z': 0.0045662100456621,\n",
       "  'Mandelentzündung': 0.0045662100456621,\n",
       "  'Mittelohrentzündung': 0.0045662100456621,\n",
       "  'Rache': 0.0045662100456621,\n",
       "  'darüber': 0.0045662100456621,\n",
       "  'Verletzung': 0.0045662100456621,\n",
       "  'angrenzend': 0.0045662100456621,\n",
       "  'Struktur': 0.0045662100456621,\n",
       "  'beispielsweise': 0.0045662100456621,\n",
       "  'Speiseröhre': 0.0045662100456621,\n",
       "  'führen': 0.0091324200913242,\n",
       "  'Rahmen': 0.0045662100456621,\n",
       "  'Bildung': 0.0045662100456621,\n",
       "  'Abszessen': 0.0045662100456621,\n",
       "  'kommen': 0.0091324200913242,\n",
       "  'klinisch': 0.0091324200913242,\n",
       "  'Erscheinungsbild': 0.0045662100456621,\n",
       "  'charakteristisch': 0.0045662100456621,\n",
       "  'stark': 0.0045662100456621,\n",
       "  'Halsschmerz': 0.0045662100456621,\n",
       "  'seitenbetont': 0.0045662100456621,\n",
       "  'Fieber': 0.0045662100456621,\n",
       "  'Halsregion': 0.0045662100456621,\n",
       "  'erheblich': 0.0045662100456621,\n",
       "  'Druckschmerzhaftigkeit': 0.0045662100456621,\n",
       "  'kennzeichnen': 0.0045662100456621,\n",
       "  'Entzündungsreaktion': 0.0045662100456621,\n",
       "  'Schwellung': 0.0045662100456621,\n",
       "  'Rötung': 0.0045662100456621,\n",
       "  'Komplikation': 0.0182648401826484,\n",
       "  'schwer': 0.0045662100456621,\n",
       "  'Blutvergiftung': 0.0045662100456621,\n",
       "  'Sepsis': 0.0045662100456621,\n",
       "  'Mediastinums': 0.0045662100456621,\n",
       "  'Mediastinitis': 0.0045662100456621,\n",
       "  'Einführung': 0.0045662100456621,\n",
       "  'Antibiotikatherapie': 0.0045662100456621,\n",
       "  'allerdings': 0.0045662100456621,\n",
       "  'Diagnose': 0.0091324200913242,\n",
       "  'Merkmal': 0.0045662100456621,\n",
       "  'Anamnese': 0.0045662100456621,\n",
       "  'körperlich': 0.0045662100456621,\n",
       "  'Untersuchung': 0.0091324200913242,\n",
       "  'Laborparameter': 0.0045662100456621,\n",
       "  'Ultraschall': 0.0091324200913242,\n",
       "  'mikrobiologisch': 0.0045662100456621,\n",
       "  'Feinnadelaspiration': 0.0091324200913242,\n",
       "  'gewonnen': 0.0045662100456621,\n",
       "  'Material': 0.0045662100456621,\n",
       "  'relativ': 0.0045662100456621,\n",
       "  'sicher': 0.0045662100456621,\n",
       "  'stellen': 0.0045662100456621,\n",
       "  'Blutuntersuchung': 0.0045662100456621,\n",
       "  'typisch': 0.0091324200913242,\n",
       "  'Veränderung': 0.0045662100456621,\n",
       "  'Erhöhung': 0.0091324200913242,\n",
       "  'Entzündungsparameter': 0.0045662100456621,\n",
       "  'heißen': 0.0045662100456621,\n",
       "  'Blutsenkungsgeschwindigkeit': 0.0045662100456621,\n",
       "  'Bsg': 0.0045662100456621,\n",
       "  'proteins': 0.0045662100456621,\n",
       "  'crp': 0.0045662100456621,\n",
       "  'Zahl': 0.0045662100456621,\n",
       "  'weiß': 0.0045662100456621,\n",
       "  'Blutkörperchen': 0.0045662100456621,\n",
       "  'Leukozytose': 0.0045662100456621,\n",
       "  'Linksverschiebung': 0.0045662100456621,\n",
       "  'Schilddrüsenparameter': 0.0045662100456621,\n",
       "  'Tsh': 0.0045662100456621,\n",
       "  'frei': 0.0045662100456621,\n",
       "  'Schilddrüsenhormone': 0.0045662100456621,\n",
       "  'Sinn': 0.0045662100456621,\n",
       "  'mild': 0.0045662100456621,\n",
       "  'Hyperthyreose': 0.0045662100456621,\n",
       "  'verändern': 0.0045662100456621,\n",
       "  'zeigen': 0.0045662100456621,\n",
       "  'inhomogen': 0.0045662100456621,\n",
       "  'Bild': 0.0045662100456621,\n",
       "  'echoarme': 0.0045662100456621,\n",
       "  'wechseln': 0.0045662100456621,\n",
       "  'echofrei': 0.0045662100456621,\n",
       "  'Areal': 0.0045662100456621,\n",
       "  'ab': 0.0045662100456621,\n",
       "  'Ultraschalluntersuchung': 0.0045662100456621,\n",
       "  'eventuell': 0.0045662100456621,\n",
       "  'Abszesse': 0.0045662100456621,\n",
       "  'nachweisen': 0.0045662100456621,\n",
       "  'dienen': 0.0045662100456621,\n",
       "  'Erregernachweis': 0.0045662100456621,\n",
       "  'Anfertigung': 0.0045662100456621,\n",
       "  'Antibiogramms': 0.0091324200913242,\n",
       "  'sinnvoll': 0.0045662100456621,\n",
       "  'Auswahl': 0.0045662100456621,\n",
       "  'Antibiotikum': 0.0045662100456621,\n",
       "  'erfolgen': 0.0136986301369863,\n",
       "  'Therapie': 0.0136986301369863,\n",
       "  'Gefahr': 0.0045662100456621,\n",
       "  'schwerwiegend': 0.0045662100456621,\n",
       "  'sofort': 0.0045662100456621,\n",
       "  'behandeln': 0.0045662100456621,\n",
       "  'Breitbandantibiotikum': 0.0045662100456621,\n",
       "  'Antibiose': 0.0045662100456621,\n",
       "  'Eintreffen': 0.0045662100456621,\n",
       "  'Untersuchungsergebnis': 0.0045662100456621,\n",
       "  'anpassen': 0.0045662100456621,\n",
       "  'Abszessbildung': 0.0045662100456621,\n",
       "  'chirurgisch': 0.0045662100456621,\n",
       "  'Eingriff': 0.0045662100456621,\n",
       "  'Ausräumung': 0.0045662100456621,\n",
       "  'Abszesses': 0.0045662100456621,\n",
       "  'Quelle': 0.0045662100456621,\n",
       "  'a': 0.0045662100456621,\n",
       "  'Heufelder': 0.0045662100456621,\n",
       "  'Thyreoiditiden': 0.0045662100456621,\n",
       "  'aktuell': 0.0045662100456621,\n",
       "  'Stand': 0.0045662100456621,\n",
       "  'Pathogenese': 0.0045662100456621,\n",
       "  'Diagnostik': 0.0045662100456621,\n",
       "  'Dtsch': 0.0045662100456621,\n",
       "  'Arztebl': 0.0045662100456621,\n",
       "  '1998': 0.0045662100456621,\n",
       "  '95': 0.0045662100456621,\n",
       "  '9': 0.0045662100456621,\n",
       "  'Mönig': 0.0045662100456621,\n",
       "  'Harbeck': 0.0045662100456621,\n",
       "  'dmw': 0.0045662100456621,\n",
       "  'Deutsche': 0.0045662100456621,\n",
       "  'medizinisch': 0.0045662100456621,\n",
       "  'Wochenschrift': 0.0045662100456621,\n",
       "  '133': 0.0045662100456621,\n",
       "  '2008': 0.0045662100456621,\n",
       "  'S': 0.0045662100456621},\n",
       " 'infekt')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir mischen die Daten und teilen in Test- und Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data = data[:160]\n",
    "test_data = data[160:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns jetzt mal ein Dokument an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt für jedes Dokument einene Merkmalsvektor. Man merke: der Vektor ist eigentlich so lang wie die Anzahl der unterschiedlichen Wörter in der ganzen Sammlung. Alle Wörter, die nicht erwähnt werden haben den Wert 0. \n",
    "\n",
    "Wörter, die nur in ein oder zwei Dokumementen vorkommen sind, für die Klassifikation nicht besonders nützlich. \n",
    "Wir nutzen nachher nur die Wörter, die in mindestens 5 Dokumente vorkommen. Um das vorzubereiten, berechnen wir für alle Wörter die Dokumentfrequenz>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq = Counter()\n",
    "for (wfreq,c) in train_data:\n",
    "    docfreq.update(wfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation mit Scikit Learn\n",
    "\n",
    "Die Bibliothek Scikit Learn stellt verschiedene Klassifikationsmodelle zur Verfügung. Wir müssen jetzt richtige Merkmalsvektoren aufbauen, bei denen die Position die Bedeutung einer Zahl bestimmt. Dazu machen wir erst eine feste Liste mit allen Wörtern. Wörter, die zu selten sind lassen wir weg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "\n",
    "allfeatures = [w for w in docfreq if docfreq[w] > 4]\n",
    "\n",
    "def make_feat_vec(featmap,featlist):\n",
    "    vec = []\n",
    "    for f in featlist:\n",
    "        vec.append(featmap.get(f,0.0))\n",
    "    return vec\n",
    "\n",
    "train_vec =  [make_feat_vec(feats,allfeatures) for feats,cls in train_data]\n",
    "train_label = [cls for feats,cls in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir schauen uns mal einen Vektor an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vec[135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kardiologie'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[137]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein einfaches, aber effektives Klassifikationsmodell, das meistens gute Ergebnisse liefert, ist die logistische Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\r71-dn9-u1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e9,verbose=True)\n",
    "logreg.fit(train_vec,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können jetzt mit dem trainierten Classifier ein neues Dokument klassifizieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['krebs'], dtype='<U11')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = make_feat_vec(test_data[17][0],allfeatures) \n",
    "logreg.predict([v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richtig ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'krebs'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[17][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder direkt für alles Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = [make_feat_vec(feats,allfeatures) for feats,cls in test_data]\n",
    "test_label = [cls for feats,cls in test_data]\n",
    "\n",
    "pred_label = list(logreg.predict(test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f-Faktor\n",
    "Recall\n",
    "Precision\n",
    "Stearman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo sind aber die Fehler aufgetreten? Un diese Frage zu beantworten, ist sogenannte eine _Konfusionsmatrix_ sehr hilfreich. NLTK hat eine Funktion zum erstellen eines Konfusionsmatrizen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            |     k     p |\n",
      "            |     a     n |\n",
      "            |     r     e |\n",
      "            |     d     u |\n",
      "            |     i     m |\n",
      "            |  i  o     o |\n",
      "            |  n  l  k  l |\n",
      "            |  f  o  r  o |\n",
      "            |  e  g  e  g |\n",
      "            |  k  i  b  i |\n",
      "            |  t  e  s  e |\n",
      "------------+-------------+\n",
      "     infekt |<10> .  .  . |\n",
      "kardiologie |  . <8> .  6 |\n",
      "      krebs |  .  . <6> . |\n",
      "pneumologie |  2  .  . <8>|\n",
      "------------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(test_label, pred_label)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt verschiedene andere Klassifikatorn, die wie nutzen können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_vec,train_label)\n",
    "pred_label = list(knn.predict(test_vec))\n",
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0 Prozent korrekt\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(train_vec,train_label)\n",
    "pred_label = list(rf.predict(test_vec))\n",
    "correct = 0\n",
    "for i in range(len(test_label)):\n",
    "    if test_label[i] == pred_label[i]:\n",
    "        correct+=1\n",
    "print(\"{0:.1f} Prozent korrekt\".format(100* float(correct)/len(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
